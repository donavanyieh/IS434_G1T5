{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94f43f22-9491-40ed-bc8c-ba4985038dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce15b1a-7120-462d-b905-f5ab4f58198a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logging in Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "83697d81-d320-4fa4-8c54-96c8804ee210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instagram_login(driver, username, password):\n",
    "        \"\"\"\n",
    "        Returns driver logged in to instagram\n",
    "        \"\"\"\n",
    "\n",
    "        # Login url\n",
    "        driver.get('https://www.instagram.com/accounts/login/?source=auth_switcher')\n",
    "\n",
    "        # Wait 3 seconds to make instagram think I'm a human\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Find username field\n",
    "        username_input = driver.find_element_by_css_selector(\"input[name='username']\")\n",
    "\n",
    "        # Click on username field\n",
    "        driver.execute_script(\"arguments[0].click();\", username_input)\n",
    "\n",
    "        # Send username\n",
    "        username_input.send_keys(username)\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Find password field\n",
    "        try:\n",
    "            password_input = driver.find_element_by_css_selector(\"input[name='password']\")\n",
    "\n",
    "        except:\n",
    "            password_input = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]/div/label/input')\n",
    "\n",
    "        # Click on password field\n",
    "        driver.execute_script(\"arguments[0].click();\", password_input)\n",
    "        \n",
    "        # Send password\n",
    "        password_input.send_keys(password)\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        # Find and click log in button\n",
    "        login_button = driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", login_button)\n",
    "    \n",
    "        time.sleep(10)\n",
    "        \n",
    "        return driver, True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea41785-b8ab-4eb4-9dcd-5da4d221f729",
   "metadata": {},
   "source": [
    "# Getting url of posts with hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b90ace4f-dce5-4c73-8a4c-2e11a819ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(hashtag, driver):\n",
    "    \"\"\"\n",
    "    Scrape unique post links from instagram using Selenium\n",
    "    Returns links of posts containing hashtag\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    \n",
    "    hashtag_url = f\"https://www.instagram.com/explore/tags/{hashtag}/\"\n",
    "    driver.get(hashtag_url)\n",
    "    \n",
    "    # Gets scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # List for unique instagram links\n",
    "    unique_links = []\n",
    "    \n",
    "    # Loop until page ends\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        page_source = driver.page_source\n",
    "        page_data = BeautifulSoup(page_source, \"html.parser\")\n",
    "        data_body = page_data.find(\"body\")\n",
    "        \n",
    "        for unique_link in data_body.findAll(\"a\"):\n",
    "            if re.match(\"/p\", unique_link.get('href')):\n",
    "                unique_links.append(f\"https://www.instagram.com{unique_link.get('href')}\")\n",
    "            \n",
    "        # Scroll to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(10)\n",
    "        \n",
    "        # If new height equal to previous screen height, break because no more content\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        time.sleep(10)\n",
    "        if last_height == new_height:\n",
    "            break\n",
    "        else:\n",
    "            last_height = new_height\n",
    "        \n",
    "        # Update on scraping\n",
    "        \n",
    "        print (f\"Scraped {len(unique_links)} links, {len(set(unique_links))} unique links\")\n",
    "        \n",
    "    print(f\"Finished scraping. Scraped {len(unique_links)} links, {len(set(unique_links))} unique links\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Closing driver.\")\n",
    "    driver.quit()\n",
    "    unique_links = list(set(unique_links))\n",
    "    return unique_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5c624d71-083f-4851-a3b5-9c2e1a851555",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('../util/chromedriver.exe')\n",
    "driver, status = instagram_login(driver, \"IS434_G1T5\", \"IS434@g1t5\")\n",
    "hashtag = \"hawkerculturesg\"\n",
    "if status:\n",
    "    unique_links = scrape_links(hashtag, driver)\n",
    "else:\n",
    "    print(\"Error logging in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70027e-5753-4575-a1a6-d0191135c4c2",
   "metadata": {},
   "source": [
    "# Getting Caption from Post URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0622df22-8e22-4fe7-99ae-83e5f6ba5913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "#justsaying, #singaporenews, #uniqlo, #supportlocalsg, #hawkerculturesg, #hawkerfood, #hawkerculture, #singapore, #singaporelife, #singaporelifestyle\n",
      "error at index: 14\n",
      "20\n",
      "#1-30., #wheretodapao, #supportlocalsg, #supportsghawkers, #sgfoodies, #whattoeat, #sgeats, #muslimfood, #ayampenyet, #hawkerculturesg, #dabaosg\n",
      "30\n",
      "#singaporeanindian, #singaporeanindiannarrative, #singaporean, #singaporehistory, #singapore, #indianexpats, #expatlivingsg, #expatsingapore, #expatsg, #singaporeculture, #singaporeheritage, #covid_19singapore, #covid, #covid_19, #coronavirussingapore, #ᴠᴀᴄᴄɪɴᴇssᴀᴠᴇʟɪᴠᴇs, #hawkerfoodsg, #hawkerculture, #hawkerculturesg, #sgfood, #sgfoodies, #sgfooddiary\n",
      "40\n",
      "\n",
      "50\n",
      "#hawkerculturesg\n",
      "60\n",
      "#instafoodsg, #instafood, #locateats, #localjiak, #sgeats, #sgfoodie, #foodiesg, #sgfood, #hawkerculturesg, #hawkerfoodsg, #hawkerfood, #sghawkerfood, #localdelights, #supportlocalsg, #lunch, #fooddiarysg, #nasilemak, #meesiam, #laksa, #changicitypoint_sg\n",
      "70\n",
      "#queenstown, #queenstownfood, #sghawker, #supportlocal, #supporthawkers, #abcbrickworksmarket, #abcmarket, #abcbrickworksfoodcentre, #hawkerfoodsg, #hawkerculturesg\n",
      "error at index: 78\n",
      "80\n",
      "#denial, #satay, #sugarcanejuice, #hawkerlegacy, #hawkercentre, #hawkerfood, #hawkerculturesg, #hawkerculture, #travel2021, #traveldiary, #travelathome, #touristinhomecountry, #food, #localfood, #localeats, #localculture, #airportfood\n",
      "90\n",
      "#livelife, #livelifetothefullest, #curious, #singaporefood, #singaporefoodie, #foodporn, #exploration, #lifeblog, #lifeblogger, #grateful, #foodcoma, #lifestories, #grateful, #hawkerfood, #hawkerculture, #hawkerculturesg, #noodles\n",
      "error at index: 94\n",
      "100\n",
      "#01-17, #DCfoodjournal, #angmokiolohmeelaksa, #lormee, #lormeesg, #hawker, #hawkerfood, #hawkercentre, #sghawker, #hawkerfoodsg, #hawkersg, #sghawkerfood, #hawkerculture, #hawkerculturesg, #sgfood, #sgfoodies, #sgfoodie, #sgeats, #sgfoodtrend, #sgfoodblogger, #burpple, #sgfoodporn, #singaporefood, #sgfooddiary\n",
      "110\n",
      "#singaporefood, #hawkerculturesg\n",
      "120\n",
      "#glutenfreesg, #vegansg, #vegetariansg, #dessertsg, #ondehondehcake, #localbusiness, #hawkerculturesg, #dessertsg, #agaragar, #agarcakesingapore, #nokonnyaku, #nokonjac, #beoriginal, #beextraordinary, #besurprised\n",
      "130\n",
      "#wheretodapao, #sgfood, #wheretodapao, #livetoeat, #food, #hawkerfoodsg, #yapkeewantonmee, #wantonmee, #hawkerfood, #sghawker, #hawkerculture, #hawkerfoodsg, #hawkerculturesg, #sgfoodies, #sgfoodporn, #eatoutsg, #singaporefood, #singaporefoodie, #instafood, #foodie, #foodstagram, #foodgasm, #eatingfortheinsta, #eatbooksg\n",
      "140\n",
      "#hawkerfoodsg, #hawkercentre, #hawkerculturesg, #newton, #newtonfoodcentre, #sgfoodies\n",
      "150\n",
      "#genz, #youth, #like, #follow, #lfl, #f4f, #tbt, #instagood, #instadaily, #hawkerculturesg, #cuisine, #history, #singaporeheritage, #legacy, #foodinsg\n",
      "160\n",
      "#gracefulleeKallang\n",
      "170\n",
      "#吃不到不要怪我, #chinhogaixiao, #chinhojiak, #甄好吃, #甄好介绍, #supporthawker, #supportlocal, #hawkerfoodsg, #hawkerfood, #hawkersg, #hawkerculturesg, #hawkercentre, #hawker, #hawkerculture, #ourhawkerculture, #singaporefood, #singaporefoodie, #singaporehawkerfood, #sgfoodie, #sgfood, #sghawker, #sghawkerculture, #singaporefoodculture, #redhill, #redhillcoffeeshop, #vegetarian, #vegetarianbeehoon\n",
      "error at index: 171\n",
      "180\n",
      "#supportlocalsg, #supporthawker, #supporthawkerfood, #supporthawkersg, #hawkerfood, #hawkersg, #hawkerfoodsg, #hawkercentre, #hawkerculture, #hawkerculturesg, #sgfood, #sgfoodies, #sgfoodtrend, #sgfoodtrend, #sgfoodlover, #sgfooddiary, #sgfoodblogger, #sgfoodreview, #sgfoodstagram, #sgfoodblog, #sgvegetarians, #sgvegetarian, #yourdailynibbles\n",
      "190\n",
      "#hawkerculturesg\n",
      "200\n",
      "#01-39, #DCfoodjournal, #anoodlestory, #ramen, #ramensg, #hawker, #hawkerfood, #hawkercentre, #sghawker, #hawkerfoodsg, #hawkersg, #sghawkerfood, #hawkerculture, #hawkerculturesg, #sgfood, #sgfoodies, #instafood, #foodstagram, #foodie, #sgfoodie, #sgeats, #foodphotography, #sgfoodtrend, #sgfoodblogger, #burpple, #igfood, #sgfoodporn, #singaporefood, #sgfooddiary\n",
      "210\n",
      "#DCfoodjournal, #sweeguanhokkienmee, #hokkienmee, #hawker, #hawkerfood, #hawkercentre, #sghawker, #hawkerfoodsg, #hawkersg, #sghawkerfood, #hawkerculture, #hawkerculturesg, #sgfood, #sgfoodies, #foodie, #sgfoodie, #sgeats, #sgfoodtrend, #sgfoodblogger, #burpple, #sgfoodporn, #singaporefood, #sgfooddiary\n",
      "error at index: 219\n",
      "220\n",
      "Error\n",
      "error at index: 221\n",
      "230\n",
      "#thepeaksg, #hawkerculturesg, #geylangbriyanistall, #168currychicken, #lorbakmama, #gubakkia\n",
      "240\n",
      "#glutenfreesg, #vegansg, #vegetariansg, #dessertsg, #localbusiness, #hawkerculturesg, #dessertsg, #agaragar, #agarcakesingapore, #nokonnyaku, #nokonjac, #beoriginal, #beextraordinary, #besurprised, #wahoo, #localdessert\n",
      "250\n",
      "#instafoodsg, #instafood, #locateats, #sgeats, #localjiak, #sgfoodie, #foodiesg, #sgfood, #hawkerculturesg, #hawkerfoodsg, #hawkerfood, #sghawkerfood, #yummy, #dinner\n",
      "260\n",
      "#meepoktah, #meepok, #bakchormee, #bcm, #mincedporknoodles, #fishballnoodles, #honglimfoodcentre, #chinatown, #hawkercentre, #hawkerfood, #hawkerfoodsg, #hawkerculture, #hawkerculturesg, #sgfood, #singaporefood, #localfood, #foodporn, #foodpornsg, #instafood, #instafoodsg, #foodgram, #foodgramsg, #foodstagram, #foodblogger, #foodbloggerSG, #foodies, #foodshare, #foodgasm, #foodforthought\n",
      "270\n",
      "#movingplates, #lino, #linocutprint, #linocut, #linoprint, #linoleumprint, #linocutting, #linoprinting, #print, #prints, #printmaking, #printstudio, #printmaker, #printmakingart, #printmakingstudio, #awagami, #awagamipaper, #cranfieldcolours, #ironfrogpress, #singapore, #singaporefood, #hawkerfood, #hawkerfoodsg, #hawkerculturesg\n",
      "280\n",
      "#nasilemak, #chinesenasilemak, #tanjongpagar, #chinhogaixiao, #chinhojiak, #甄好吃, #甄好介绍, #supporthawker, #supportlocal, #hawkerfoodsg, #hawkerfood, #hawkersg, #hawkerculturesg, #hawkercentre, #hawker, #hawkerculture, #ourhawkerculture, #singaporefood, #singaporefoodie, #singaporehawkerfood, #sgfoodie, #sgfood, #sghawker, #sghawkerculture, #singaporefoodculture\n",
      "error at index: 288\n",
      "290\n",
      "#staysafe, #stayhealthy, #rwp, #eidmubarak, #amoystreetfoodcenter, #amoystreetfoodcentre, #hawkerculture, #hawkerculturesg, #sghawkerfood, #halalsg, #rayyanswaroengupnormal, #foodstagram, #instafood, #foodporn, #hariraya, #eidilfitri\n",
      "300\n",
      "#01-17,, #DCfoodjournal, #oldshifucharcoalporridge, #cantoneseporridge, #hawker, #hawkerfood, #hawkercentre, #sghawker, #hawkerfoodsg, #hawkersg, #sghawkerfood, #hawkerculture, #hawkerculturesg, #sgfood, #sgfoodies, #foodie, #sgfoodie, #sgeats, #sgfoodtrend, #sgfoodblogger, #burpple, #sgfoodporn, #singaporefood, #sgfooddiary\n",
      "310\n",
      "#hawkerculturesg, #sghawkerfood\n",
      "320\n",
      "#culturespoonsg, #coworkingkitchen, #sgfood, #sgfoodie, #nyonyafusion, #nasilemak, #bluepea, #butterflypea, #rendangchicken, #jiaklocal, #hawkerculturesg\n",
      "Output to ../data/instagram_hashtag_posts.csv\n"
     ]
    }
   ],
   "source": [
    "def get_hashtags(driver, links):\n",
    "    \"\"\"\n",
    "    Takes in instagram post URLs\n",
    "    Returns hashtags in instagram post, seperated by comma\n",
    "    \"\"\"\n",
    "    hashtags_list = []\n",
    "    error_count = 0\n",
    "    for index,link in enumerate(links):\n",
    "        try:\n",
    "            if index%10==0:\n",
    "                print(index)\n",
    "                try:\n",
    "                    print(hashtags_list[-1])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            driver.get(link)\n",
    "            time.sleep(5)\n",
    "            driver.refresh()\n",
    "            time.sleep(10)\n",
    "            page_source = driver.page_source\n",
    "            raw_data = BeautifulSoup(page_source, \"html.parser\")\n",
    "            data = raw_data.find_all(\"body\")[0].find_all(\"script\")[11]\n",
    "            json_data = json.loads(data.text.strip().replace('window._sharedData =', '').replace(';', '')[:-1].split(\",\",1)[1])\n",
    "            caption = json_data[\"items\"][0][\"caption\"][\"text\"]\n",
    "            words_from_post = caption.split()\n",
    "\n",
    "            post_hashtags = []\n",
    "            for word in words_from_post:\n",
    "                if word[0] == \"#\":\n",
    "                    post_hashtags.append(word)\n",
    "            post_hashtags = \", \".join(post_hashtags)\n",
    "            hashtags_list.append(post_hashtags)\n",
    "            time.sleep(8)\n",
    "        except:\n",
    "            error_count+=1\n",
    "            print(f\"error at index: {index}\")\n",
    "            hashtags_list.append(\"Error\")\n",
    "    return hashtags_list\n",
    "\n",
    "hashtags_list = get_hashtags(driver, unique_links) \n",
    "\n",
    "# Convert to dataframe and export as csv\n",
    "hashtags_df = pd.DataFrame(list(zip(unique_links, hashtags_list)),\n",
    "               columns = ['post_url', 'hashtags'])\n",
    "\n",
    "output_path = \"../data/instagram_hashtag_posts.csv\"\n",
    "hashtags_df.to_csv(output_path)\n",
    "print(f\"Output to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
