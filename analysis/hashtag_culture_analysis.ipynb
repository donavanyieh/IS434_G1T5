{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb886b93-1ca3-41c2-aa1d-d86ac2592f6c",
   "metadata": {},
   "source": [
    "# Hashtag Culture Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4c3b2-c2ec-4f4a-a68c-8453b4c3f590",
   "metadata": {},
   "source": [
    "A hashtag (#) is a type of metadata tag used on social networks such as Twitter and other microblogging services. It lets users apply dynamic, user-generated tagging that helps other users easily find messages with a specific theme or content. We can borrow some basic principles from Network Science and graph theory to understand how hashtags on Instagram are connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3a9fb-51b9-4747-a35d-11620388c379",
   "metadata": {},
   "source": [
    "# What aspects of Graph Theory can we use in our analysis?\n",
    "<ul>\n",
    "    <li><b>Community Detection</b>: We can use algorithms to identify and label clusters of topics/themes</li>\n",
    "    <li><b>Degree Centrality/ Betweenness Centrality</b>: We can calculate what hashtags in the network are particularly important in linking the whole network.</li>\n",
    "    <li><b>Visualization</b>: If we plot the network using scatterplots, itâ€™s a very compelling way to visualise a huge amount of information about hashtags that would be cumbersome to do otherwise</li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94f43f22-9491-40ed-bc8c-ba4985038dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce15b1a-7120-462d-b905-f5ab4f58198a",
   "metadata": {},
   "source": [
    "# Logging in Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83697d81-d320-4fa4-8c54-96c8804ee210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instagram_login(driver, username, password):\n",
    "        \"\"\"\n",
    "        Returns driver logged in to instagram\n",
    "        \"\"\"\n",
    "\n",
    "        # Login url\n",
    "        driver.get('https://www.instagram.com/accounts/login/?source=auth_switcher')\n",
    "\n",
    "        # Wait 3 seconds to make instagram think I'm a human\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Find username field\n",
    "        username_input = driver.find_element_by_css_selector(\"input[name='username']\")\n",
    "\n",
    "        # Click on username field\n",
    "        driver.execute_script(\"arguments[0].click();\", username_input)\n",
    "\n",
    "        # Send username\n",
    "        username_input.send_keys(username)\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Find password field\n",
    "        try:\n",
    "            password_input = driver.find_element_by_css_selector(\"input[name='password']\")\n",
    "\n",
    "        except:\n",
    "            password_input = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]/div/label/input')\n",
    "\n",
    "        # Click on password field\n",
    "        driver.execute_script(\"arguments[0].click();\", password_input)\n",
    "        \n",
    "        # Send password\n",
    "        password_input.send_keys(password)\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        # Find and click log in button\n",
    "        login_button = driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", login_button)\n",
    "    \n",
    "        time.sleep(10)\n",
    "        \n",
    "        return driver, True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea41785-b8ab-4eb4-9dcd-5da4d221f729",
   "metadata": {},
   "source": [
    "# Getting url of posts with hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b90ace4f-dce5-4c73-8a4c-2e11a819ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(hashtag, driver):\n",
    "    \"\"\"\n",
    "    Scrape unique post links from instagram using Selenium\n",
    "    Returns links of posts containing hashtag\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    \n",
    "    hashtag_url = f\"https://www.instagram.com/explore/tags/{hashtag}/\"\n",
    "    driver.get(hashtag_url)\n",
    "    \n",
    "    # Gets scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # List for unique instagram links\n",
    "    unique_links = []\n",
    "    \n",
    "    # Loop until page ends\n",
    "    while True:\n",
    "        time.sleep(10)\n",
    "        page_source = driver.page_source\n",
    "        page_data = BeautifulSoup(page_source, \"html.parser\")\n",
    "        data_body = page_data.find(\"body\")\n",
    "        \n",
    "        for unique_link in data_body.findAll(\"a\"):\n",
    "            if re.match(\"/p\", unique_link.get('href')):\n",
    "                unique_links.append(f\"https://www.instagram.com{unique_link.get('href')}\")\n",
    "            \n",
    "        # Scroll to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(10)\n",
    "        \n",
    "        # If new height equal to previous screen height, break because no more content\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        time.sleep(10)\n",
    "        if last_height == new_height:\n",
    "            break\n",
    "        else:\n",
    "            last_height = new_height\n",
    "        \n",
    "        # Update on scraping\n",
    "        \n",
    "        print (f\"Scraped {len(unique_links)} links, {len(set(unique_links))} unique links\")\n",
    "        \n",
    "    print(f\"Finished scraping. Scraped {len(unique_links)} links, {len(set(unique_links))} unique links\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Closing driver.\")\n",
    "    driver.quit()\n",
    "    unique_links = list(set(unique_links))\n",
    "    return unique_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c624d71-083f-4851-a3b5-9c2e1a851555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 21 links, 21 unique links\n",
      "Scraped 54 links, 33 unique links\n",
      "Scraped 93 links, 39 unique links\n",
      "Scraped 141 links, 51 unique links\n",
      "Scraped 189 links, 63 unique links\n",
      "Scraped 228 links, 66 unique links\n",
      "Scraped 276 links, 78 unique links\n",
      "Scraped 324 links, 90 unique links\n",
      "Scraped 366 links, 96 unique links\n",
      "Scraped 414 links, 108 unique links\n",
      "Scraped 462 links, 120 unique links\n",
      "Scraped 504 links, 126 unique links\n",
      "Scraped 552 links, 138 unique links\n",
      "Scraped 600 links, 150 unique links\n",
      "Scraped 642 links, 156 unique links\n",
      "Scraped 690 links, 168 unique links\n",
      "Scraped 738 links, 180 unique links\n",
      "Scraped 777 links, 183 unique links\n",
      "Scraped 828 links, 198 unique links\n",
      "Scraped 870 links, 204 unique links\n",
      "Scraped 921 links, 219 unique links\n",
      "Scraped 969 links, 231 unique links\n",
      "Scraped 1008 links, 234 unique links\n",
      "Scraped 1059 links, 249 unique links\n",
      "Scraped 1107 links, 261 unique links\n",
      "Scraped 1161 links, 279 unique links\n",
      "Scraped 1209 links, 291 unique links\n",
      "Scraped 1263 links, 309 unique links\n",
      "Finished scraping. Scraped 1311 links, 321 unique links\n",
      "\n",
      "\n",
      "Closing driver.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('../util/chromedriver.exe')\n",
    "driver, status = instagram_login(driver, \"IS434_G1T5\", \"IS434@g1t5\")\n",
    "hashtag = \"hawkerculturesg\"\n",
    "if status:\n",
    "    unique_links = scrape_links(hashtag, driver)\n",
    "else:\n",
    "    print(\"Error logging in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0622df22-8e22-4fe7-99ae-83e5f6ba5913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "def get_hashtags(url):\n",
    "    \"\"\"\n",
    "    Takes in instagram post URLs\n",
    "    Returns hashtags in instagram post, seperated by comma\n",
    "    \"\"\"\n",
    "    page = requests.get(url)\n",
    "    data = BeautifulSoup(page.content, \"html.parser\")\n",
    "    body_data = data.find(\"body\")\n",
    "    script = body.find(\"script\")\n",
    "\n",
    "    raw_data = script.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "    json_data = json.loads(raw_data)\n",
    "    words_from_post = json_data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['edge_media_to_caption']['edges'][0]['node']['text'].split()\n",
    "    \n",
    "    post_hashtags = []\n",
    "    for word in words_from_post:\n",
    "        if word[0] == \"#\":\n",
    "            post_hashtags.append(word)\n",
    "    post_hashtags = \", \".join(post_hashtags)\n",
    "    return post_hashtags\n",
    "\n",
    "\n",
    "# Loop through instagram url and append hashtags into list\n",
    "hashtags_list = []\n",
    "for index,url in enumerate(unique_links):\n",
    "    post_hashtags = get_hashtags(url)\n",
    "    hashtags_list.append(post_hashtags)\n",
    "    # Track progress\n",
    "    if index%10==0:\n",
    "        print(index)\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1d86ccda-2872-409a-83a6-b62ce74c3abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.instagram.com/p/CQ--UmMH_i8/',\n",
       " 'https://www.instagram.com/p/CUhn24DKP0A/',\n",
       " 'https://www.instagram.com/p/CNUz7jPnpJK/',\n",
       " 'https://www.instagram.com/p/CZlBMnEPFcy/',\n",
       " 'https://www.instagram.com/p/COcNod6nOhv/']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "670781aa-be52-43ba-83ac-72fd191a19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe and export as csv\n",
    "hashtags_df = pd.DataFrame(list(zip(unique_links, hashtags_list)),\n",
    "               columns =['post_url', 'hashtags'])\n",
    "hashtags_df.to_csv(\"../data/instagram_hashtag_posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13696c27-e4c3-4b4f-b8ed-ca6ee874bb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
