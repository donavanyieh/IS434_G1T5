{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb886b93-1ca3-41c2-aa1d-d86ac2592f6c",
   "metadata": {},
   "source": [
    "# Hashtag Culture Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4c3b2-c2ec-4f4a-a68c-8453b4c3f590",
   "metadata": {},
   "source": [
    "A hashtag (#) is a type of metadata tag used on social networks such as Twitter and other microblogging services. It lets users apply dynamic, user-generated tagging that helps other users easily find messages with a specific theme or content. We can borrow some basic principles from Network Science and graph theory to understand how hashtags on Instagram are connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3a9fb-51b9-4747-a35d-11620388c379",
   "metadata": {},
   "source": [
    "# What aspects of Graph Theory can we use in our analysis?\n",
    "<ul>\n",
    "    <li><b>Community Detection</b>: We can use algorithms to identify and label clusters of topics/themes</li>\n",
    "    <li><b>Degree Centrality/ Betweenness Centrality</b>: We can calculate what hashtags in the network are particularly important in linking the whole network.</li>\n",
    "    <li><b>Visualization</b>: If we plot the network using scatterplots, itâ€™s a very compelling way to visualise a huge amount of information about hashtags that would be cumbersome to do otherwise</li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f43f22-9491-40ed-bc8c-ba4985038dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83697d81-d320-4fa4-8c54-96c8804ee210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instagramLogin(driver, username, password):\n",
    "        \"\"\"\n",
    "        Returns driver logged in to instagram\n",
    "        \"\"\"\n",
    "\n",
    "        # Login url\n",
    "        driver.get('https://www.instagram.com/accounts/login/?source=auth_switcher')\n",
    "\n",
    "        # Wait 3 seconds to make instagram think I'm a human\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Find username field\n",
    "        username_input = driver.find_element_by_css_selector(\"input[name='username']\")\n",
    "\n",
    "        # Click on username field\n",
    "        driver.execute_script(\"arguments[0].click();\", username_input)\n",
    "\n",
    "        # Send username\n",
    "        username_input.send_keys(username)\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Find password field\n",
    "        try:\n",
    "            password_input = driver.find_element_by_css_selector(\"input[name='password']\")\n",
    "\n",
    "        except:\n",
    "            password_input = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]/div/label/input')\n",
    "\n",
    "        # Click on password field\n",
    "        driver.execute_script(\"arguments[0].click();\", password_input)\n",
    "        \n",
    "        # Send password\n",
    "        password_input.send_keys(password)\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        # Find and click log in button\n",
    "        login_button = driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", login_button)\n",
    "    \n",
    "        time.sleep(3)\n",
    "        return driver\n",
    "#         #locate floating window to click and close\n",
    "#         floating_window = driver.find_element_by_class_name('piCib')\n",
    "\n",
    "#         button = floating_window.find_element_by_class_name('mt3GC')\n",
    "\n",
    "#         not_now = button.find_element_by_xpath('/html/body/div[4]/div/div/div[3]/button[2]')\n",
    "\n",
    "#         driver.execute_script(\"arguments[0].click();\", not_now)\n",
    "\n",
    "#         return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f66cb7-9725-4059-bd78-df3459262db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('../util/chromedriver.exe')\n",
    "driver = instagramLogin(driver, \"IS434_G1T5\", \"IS434@g1t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90ace4f-dce5-4c73-8a4c-2e11a819ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_links(hashtag, driver):\n",
    "    \"\"\"\n",
    "    Scrape unique post links from instagram using Selenium\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    \n",
    "    hashtag_url = f\"https://www.instagram.com/explore/tags/{hashtag}/\"\n",
    "    driver.get(hashtag_url)\n",
    "    \n",
    "    # Gets scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # List for unique instagram links\n",
    "    unique_links = []\n",
    "    \n",
    "    # Loop until page ends\n",
    "    while True:\n",
    "        print(\"Iterative while loop\")\n",
    "        time.sleep(3)\n",
    "        page_source = driver.page_source\n",
    "        page_data = BeautifulSoup(page_source, \"html.parser\")\n",
    "        data_body = page_data.find(\"body\")\n",
    "        \n",
    "        for unique_link in data_body.findAll(\"a\"):\n",
    "            if re.match(\"/p\", unique_link.get('href')):\n",
    "                unique_links.append(f\"https://www.instagram.com{unique_link.get('href')}\")\n",
    "            \n",
    "        # Scroll to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        # If new height equal to previous screen height, break because no more content\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if last_height == new_height:\n",
    "            break\n",
    "        else:\n",
    "            last_height = new_height\n",
    "        \n",
    "        # Update on scraping\n",
    "        \n",
    "        print (f\"Scraped {len(unique_links)} links, {len(set(unique_links))} unique links\")\n",
    "        \n",
    "    print(f\"Finished scraping. Scraped {len(unique_links)} links, {len(set(unique_links))} unique links\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Closing driver.\")\n",
    "    driver.quit()\n",
    "    \n",
    "    return unique_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c624d71-083f-4851-a3b5-9c2e1a851555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterative while loop\n",
      "Scraped 33 links, 33 unique links\n",
      "Iterative while loop\n",
      "Scraped 72 links, 39 unique links\n",
      "Iterative while loop\n",
      "Scraped 123 links, 51 unique links\n",
      "Iterative while loop\n",
      "Scraped 177 links, 63 unique links\n",
      "Iterative while loop\n",
      "Scraped 222 links, 66 unique links\n",
      "Iterative while loop\n",
      "Scraped 276 links, 78 unique links\n",
      "Iterative while loop\n",
      "Scraped 330 links, 90 unique links\n",
      "Iterative while loop\n",
      "Scraped 378 links, 96 unique links\n",
      "Iterative while loop\n",
      "Scraped 432 links, 108 unique links\n",
      "Iterative while loop\n",
      "Scraped 486 links, 120 unique links\n",
      "Iterative while loop\n",
      "Scraped 534 links, 126 unique links\n",
      "Iterative while loop\n",
      "Scraped 588 links, 138 unique links\n",
      "Iterative while loop\n",
      "Scraped 642 links, 150 unique links\n",
      "Iterative while loop\n",
      "Finished scraping. Scraped 690 links, 156 unique links\n",
      "\n",
      "\n",
      "Closing driver.\n"
     ]
    }
   ],
   "source": [
    "hashtag = \"hawkerculturesg\"\n",
    "unique_links = scrape_links(hashtag, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925f70cc-026e-45d4-ab7c-b93a7cd7dddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(unique_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612b0be-424f-4d9d-8ba1-56a124ac3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622df22-8e22-4fe7-99ae-83e5f6ba5913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
